{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入基本的库\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入特征名称，添加label列名\n",
    "with open('data/features.txt', 'r') as fr:\n",
    "    features = np.array([line.strip().split(': ') for line in fr.readlines()])\n",
    "features = np.append(features, ['label', 'symbolic.']).reshape(-1, 2)\n",
    "symbolic_features = features[features[:, 1] == 'symbolic.'][:, 0]\n",
    "features.shape, symbolic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据文件，展示头几个样本。\n",
    "data_df = pd.read_csv('data/kddcup.data_10_percent', header=None, names=features[:, 0])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内存不够，只保留前10万行数据\n",
    "data_df.drop(data_df.index[100000:], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据规模\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列数太多，分批次查看数据，了解数据特点\n",
    "data_df.iloc[:, :14].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.iloc[:, 14:28].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.iloc[:, 28:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看标签分布\n",
    "data_df.groupby(['label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签分布极不平衡，合并标签，按攻击类别处理\n",
    "with open('data/labels.txt', 'r') as fr:\n",
    "    labels = np.array([line.strip().split(': ') for line in fr.readlines()])\n",
    "label_types = {}\n",
    "for pair in labels:\n",
    "    label_types[pair[0]] = pair[1]\n",
    "data_df['label_type'] = [label_types[label] for label in data_df['label']]\n",
    "data_df.groupby(['label_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断是否是attack\n",
    "data_df['label_attack'] = ['attack' if label != 'normal.' else 'normal' for label in data_df['label']]\n",
    "data_df.groupby(['label_attack']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有哪些列是类别特征，是否与features.txt中一致？\n",
    "data_df.columns[data_df.dtypes == 'object'], symbolic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有几个类别特征被pandas当做数值处理了，需要转换成object类型\n",
    "to_object = ['land', 'logged_in', 'is_host_login', 'is_guest_login']\n",
    "data_df[to_object] = data_df[to_object].astype('object')\n",
    "object_features = data_df.columns[data_df.dtypes == 'object']\n",
    "numberic_features = data_df.columns[data_df.dtypes != 'object']\n",
    "symbolic_features, object_features, numberic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看类别类型的数据特点，观察unique值，判断转换成独热编码的数据的规模\n",
    "data_df[object_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将类别特征转换成独热编码，label、label_type、normal是标签，不需要转换\n",
    "object_features_one_hot = pd.get_dummies(data_df[object_features[:-3]])\n",
    "# 将数据按照标签+独热编码+数值类型排列，获得用来训练和测试的数据集\n",
    "warm_df = data_df.iloc[:, -3:].join(object_features_one_hot).join(data_df[numberic_features])\n",
    "warm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签类别当做决策树的标签，将数据集分成训练数据和测试数据\n",
    "\n",
    "feature_names = np.array(warm_df.columns[3:].tolist())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    warm_df[feature_names].values, \n",
    "    warm_df['label_type'].values,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_min_samples_split = [3, 5, 7, 9]\n",
    "params_min_samples_leaf = [1, 2, 4]\n",
    "params_max_depth = np.arange(10, 51, 5)\n",
    "\n",
    "# 构造决策树，并做交叉验证\n",
    "parameters = {'min_samples_split': params_min_samples_split,\n",
    "             'min_samples_leaf': params_min_samples_leaf,\n",
    "             'max_depth': params_max_depth}\n",
    "dt_clf = DecisionTreeClassifier(criterion='entropy')\n",
    "model = GridSearchCV(dt_clf, parameters, cv=5, scoring='f1_weighted', n_jobs=4)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 输出最好的参数\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用获得的最佳参数，重新训练模型\n",
    "# best_min_samples_split = 3\n",
    "# best_min_samples_leaf = 1\n",
    "# best_max_depth = 20\n",
    "best_min_samples_split = model.best_params_['min_samples_split']\n",
    "best_min_samples_leaf = model.best_params_['min_samples_leaf']\n",
    "best_max_depth = model.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion='entropy',\n",
    "                                min_samples_split=best_min_samples_split,\n",
    "                                min_samples_leaf=best_min_samples_leaf,\n",
    "                                max_depth=best_max_depth)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# 查看在测试集上的效果\n",
    "predictions = dt_clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用同样的参数，如果只考虑标签是否为attack，结果如何？\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(\n",
    "    warm_df[feature_names].values, \n",
    "    warm_df['label_attack'].values,\n",
    "    test_size=0.2\n",
    ")\n",
    "dt_clf_1 = DecisionTreeClassifier(criterion='entropy',\n",
    "                                min_samples_split=best_min_samples_split,\n",
    "                                min_samples_leaf=best_min_samples_leaf,\n",
    "                                max_depth=best_max_depth)\n",
    "dt_clf_1.fit(X_train_1, y_train_1)\n",
    "predictions = dt_clf_1.predict(X_test_1)\n",
    "print(classification_report(y_test_1, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用同样的参数，考虑所有类型的标签呢？\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(\n",
    "    warm_df[feature_names].values, \n",
    "    warm_df['label'].values,\n",
    "    test_size=0.2\n",
    ")\n",
    "dt_clf_2 = DecisionTreeClassifier(criterion='entropy',\n",
    "                                min_samples_split=best_min_samples_split,\n",
    "                                min_samples_leaf=best_min_samples_leaf,\n",
    "                                max_depth=best_max_depth)\n",
    "dt_clf_2.fit(X_train_2, y_train_2)\n",
    "predictions = dt_clf_2.predict(X_test_2)\n",
    "print(classification_report(y_test_2, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "\n",
    "dot_data = tree.export_graphviz(dt_clf, out_file=None,\n",
    "                         feature_names=feature_names,\n",
    "                         class_names=warm_df['label_type'].unique(),\n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(\"kdd99.label_type.pdf\")\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
